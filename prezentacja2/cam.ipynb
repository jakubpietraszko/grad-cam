{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "#model = models.efficientnet_b0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.loadtxt('imagenet_classes.txt', str, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, transform):\n",
    "    '''\n",
    "    get image from path and transform it tensor\n",
    "    '''\n",
    "    img = PIL.Image.open(path)\n",
    "    img_t = transform(img)\n",
    "    print(img_t.shape)\n",
    "    img_t = img_t.unsqueeze(0)\n",
    "    return img_t\n",
    "img = get_image('images/husky.jpg', transform)\n",
    "img = get_image('images/precelek.jpg', transform)\n",
    "type(img), img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model.layer4[-1].conv3\n",
    "\n",
    "activations = []\n",
    "gradients = []\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    gradients.append(grad_out[0])\n",
    "\n",
    "target_layer = model.layer4[-1].conv3\n",
    "t1 = target_layer.register_forward_hook(forward_hook)\n",
    "t2 = target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "model.eval()\n",
    "ouput = model(img)\n",
    "pred_class = ouput.argmax().item()\n",
    "\n",
    "model.zero_grad()\n",
    "ouput[0, pred_class].backward()\n",
    "\n",
    "gradients = gradients[0].cpu().data.numpy()\n",
    "activations = activations[0].cpu().data.numpy()\n",
    "\n",
    "t1.remove()\n",
    "t2.remove()\n",
    "\n",
    "weights = activations.mean(axis=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_1000_categories = 'imagenet_classes.txt'\n",
    "categories = np.loadtxt(path_to_1000_categories, str, delimiter='\\t')\n",
    "\n",
    "category = categories[pred_class]\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgg = get_image_torch('images/husky.jpg', 224, 224)\n",
    "cam = get_cam(imgg, model, target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''overlay_plot(imgg, cam, 0.5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('images/husky.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''overlay_plot_torch(path, cam, 0.5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imgg = get_image_torch('images/husky.jpg', 224, 224)\n",
    "grad_cam = get_gradcam(imgg, model, target_layer)\n",
    "\n",
    "\n",
    "overlay_plot_torch(img, grad_cam, 0.5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imgg = get_image_torch('images/nosacz.jpg', 224, 224)\n",
    "hires_cam = get_hirescam(imgg, model, target_layer)\n",
    "\n",
    "overlay_plot(path, hires_cam, 0.5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = np.zeros(activations.shape[2:], dtype=np.float32)\n",
    "\n",
    "for i, w in enumerate(weights[0]):\n",
    "    cam += w * activations[0, i, :, :]\n",
    "\n",
    "cam = np.maximum(cam, 0)\n",
    "\n",
    "cam_temp = cam.copy()\n",
    "\n",
    "heatmap = cv2.resize(cam, (224, 224))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "heatmap_temp = heatmap.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.squeeze(0).permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(img)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[2].imshow(heatmap)\n",
    "axs[2].set_title('Heatmap')\n",
    "axs[2].axis('off')\n",
    "\n",
    "overlayed_img = heatmap * 0.5 + img\n",
    "overlayed_img = overlayed_img / overlayed_img.max()\n",
    "\n",
    "axs[1].imshow(overlayed_img)\n",
    "axs[1].set_title('Overlayed Image')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Pretrained Model\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path, target_size):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "image_path = 'images/husky.jpg'  # Replace with your image path\n",
    "preprocessed_image = preprocess_image(image_path, target_size=(224, 224))\n",
    "\n",
    "# Predict the class\n",
    "predictions = model.predict(preprocessed_image)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "decoded_prediction = decode_predictions(predictions, top=1)[0][0]\n",
    "print(f\"Predicted class: {decoded_prediction}\")\n",
    "\n",
    "# Generate CAM\n",
    "def generate_cam(model, img_array, last_conv_layer_name, class_idx):\n",
    "    # Get the output of the last convolutional layer and the output layer\n",
    "    conv_layer = model.get_layer(last_conv_layer_name).output\n",
    "    output_layer = model.output\n",
    "\n",
    "    # Create a model that maps the input image to the activations of the conv layer and predictions\n",
    "    cam_model = tf.keras.models.Model(inputs=model.input, outputs=[conv_layer, output_layer])\n",
    "\n",
    "    # Get the weights of the class in the dense layer\n",
    "    class_weights = model.layers[-1].weights[0][:, class_idx]\n",
    "\n",
    "    # Extract conv layer output and predictions\n",
    "    conv_outputs, predictions = cam_model(img_array)\n",
    "\n",
    "    # Compute the weighted sum of the feature maps\n",
    "    conv_outputs = conv_outputs[0]  # Shape: (7, 7, 2048)\n",
    "    cam = np.dot(conv_outputs, class_weights)\n",
    "\n",
    "    # Apply ReLU and normalize\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    return cam\n",
    "\n",
    "# Get the last conv layer name\n",
    "last_conv_layer_name = \"conv5_block3_out\"  # For ResNet50\n",
    "\n",
    "# Generate CAM\n",
    "class_idx = predicted_class  # Index of the predicted class\n",
    "cam = generate_cam(model, preprocessed_image, last_conv_layer_name, class_idx)\n",
    "\n",
    "heatmap_temp2 = None\n",
    "\n",
    "# Overlay CAM on the original image\n",
    "def overlay_cam(cam, image_path, alpha=0.4):\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # Resize CAM to match the image size\n",
    "    cam_resized = tf.image.resize(tf.expand_dims(cam, -1), (img.shape[0], img.shape[1])).numpy().squeeze()\n",
    "    cam_resized = np.uint8(255 * cam_resized)\n",
    "    heatmap = np.uint8(plt.cm.jet(cam_resized)[:, :, :3] * 255)\n",
    "    heatmap_temp2 = heatmap.copy()\n",
    "\n",
    "    # Superimpose CAM on the image\n",
    "    superimposed_img = heatmap * alpha + img\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(\"uint8\")\n",
    "    return superimposed_img\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "def overlay_cam(cam, image_path, alpha=0.5):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize CAM to match the image size\n",
    "    cam_resized = cv2.resize(cam, (img.shape[1], img.shape[0]))  # Resize to (width, height)\n",
    "    cam_resized = np.uint8(255 * cam_resized)  # Normalize to 0-255\n",
    "    heatmap = cv2.applyColorMap(cam_resized, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Superimpose the heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "    return superimposed_img\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the CAM\n",
    "superimposed_img = overlay_cam(cam, image_path)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(superimposed_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
